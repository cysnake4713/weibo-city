本地托管git代码

文件:
 sina/csv_encoder.py  功能类,因为python原生csv导出对中文支持不好,所以重新写了几个类帮助中文导入导出.
 sina/main.py  主要模块,包括所有功能代码.
 sina/point.csv 点文件,其实就是所有的用户信息
 sina/edge.csv 边文件,所有在point.csv中的用户直接的好友关系.

实现介绍:
 基本由一下几步实现:
 1.如果没有检测到token,则程序先获得token并且打印.
 2.在有token的情况下,执行friends_list_to_file函数,获得指定的三个微博(王富海规划,中国城市规划设计研究院,深圳市城市规划设计研究院)的所有关注人列表,但是没有去重复(后面解释为什么没有去重复).
 3.注释掉friends_list_to_file,运行from_friend_get_relation,通过当前获得的用户列表,对每一个用户,分别获得其关注信息,形成(用户id,用户关注者id)的tuple,写入到用户好友关系文件中
    这里因为受新浪微博的限制,先做了个定时器,定每个小时查询150个好友,后在使用中发现由于查询好友信息会分页,也就是说基本上每个好友信息只要需要2~3次请求才能获得.
    所以最后改为使用try 语句判断当前请求数量是否超限制,如果超限制则等待1个小时候继续请求.

 用法:
 你需要的文件就是'point.csv'和'edge.csv',文件格式如下:
 'point.csv':
    用户ID,用户名,用户所属好友

 'edge.csv'
    用户ID,用户关注用户ID

 因为point.csv 中 用户数据没有去重复,就是说会有这样的情况:有用户叫王二,他即是王富海规划的关注,又是中国城市规划设计研究院的关注,所以会在好友列表中出现两次.
 为什么没有去重复呢,有以下几点考虑,1,我看了你发来的那个图片,人家是分成3个大块的,我不知道是系统自动生成的,还是需要给参数,所以我在point.csv中预留了参数'用户所属好友'
 这样你可以通过group这个参数给人划分群,
 如果你想去重复,可以用excel打开csv(excel可以打开csv的),使用里面的工具可以去重复,并且可以统计一些信息.(用excel的分组和排序等功能,具体的可能你比我熟,我们写程序的excel用的少)
 同样edge.csv中也会有些重复,这是因为point.csv中的重复造成的,如果需要,也可以去重.

 edge_no_duplicate.csv和point_noduplicate.csv 这个是我做好的去重的,可以直接用

 或者说你对这个不是太在意,你直接把数据导入到那个画图的软件中如果能够出结果,也行,虽然有偏差,外行人估计很难看出来......
